# Verita AI - Complete Data Annotation Platform

A production-ready, enterprise-scale data annotation platform designed to compete with industry leaders like Surge AI, Scale AI, and Labelbox. Features advanced AI integration, real-time collaboration, and comprehensive enterprise features.

> **üéØ Status**: Production-ready full-stack implementation  
> **üìä Scale**: Supports thousands of users and millions of tasks  
> **üèóÔ∏è Architecture**: Modern React/TypeScript frontend + FastAPI/Python backend

## üöÄ **COMPLETE IMPLEMENTATION**

This platform includes **everything** needed for enterprise data annotation:
- ‚úÖ **Frontend**: Complete React/TypeScript application (40+ components, 15+ pages)
- ‚úÖ **Backend**: Full FastAPI implementation (60+ endpoints, 15+ database tables)  
- ‚úÖ **AI Integration**: Multi-model suggestions with confidence scoring
- ‚úÖ **Enterprise Features**: Multi-tenancy, audit trails, compliance, webhooks
- ‚úÖ **Real-time Collaboration**: Live updates, team coordination, notifications

## üèóÔ∏è **PLATFORM FEATURES**

### **üéØ Core Platform**
- **Multi-Tenant Organizations**: Complete workspace isolation with role-based access
- **Advanced Project Management**: Full lifecycle from creation to completion
- **Comprehensive Task Management**: Single, bulk, and CSV creation methods
- **AI-Powered Suggestions**: Multiple ML models with confidence scoring
- **Real-time Collaboration**: Live team coordination and communication
- **Quality Assurance**: Gold standard tasks and automated quality control

### **üìä Enterprise Features**
- **Analytics Dashboard**: Comprehensive project and team insights
- **Audit Trails**: Complete activity logging and data versioning
- **Webhook Integration**: Event-driven notifications and integrations
- **Notification System**: Real-time alerts and customizable preferences
- **Advanced Settings**: Platform configuration and feature management
- **Task Queue Management**: Intelligent task distribution and load balancing

### **ü§ñ AI Integration**
- **Auto-Labeling**: ML-powered suggestion system
- **Multiple Models**: Text classification, image recognition, NER, sentiment analysis
- **Confidence Scoring**: Quality assessment for AI predictions
- **Feedback Loop**: User feedback improves model accuracy
- **Custom Models**: Deploy and manage custom AI models

### **üîí Security & Compliance**
- **JWT Authentication**: Secure token-based authentication with refresh
- **Role-Based Access**: Granular permission system
- **Data Encryption**: End-to-end security for sensitive data
- **Audit Compliance**: Complete activity tracking for regulatory requirements
- **API Security**: Rate limiting, CORS, and input validation

## üîß **TECHNOLOGY STACK**

### **Frontend (React/TypeScript)**
- **React 18** with TypeScript for type safety
- **Vite** for fast development and optimized builds
- **TailwindCSS** for responsive, utility-first styling
- **Zustand** for lightweight state management
- **React Query** for server state and caching
- **Shadcn/ui** for accessible component library
- **React Hook Form + Zod** for form management

### **Backend (Python/FastAPI)**
- **FastAPI** (Python 3.11+) for high-performance API
- **PostgreSQL** with AsyncPG for scalable database
- **SQLAlchemy 2.0** with async support
- **JWT Authentication** with refresh tokens
- **Redis** for caching and real-time features
- **Celery** for background task processing

### **AI/ML Stack**
- **scikit-learn** for traditional ML models
- **transformers** for modern NLP models
- **PyTorch** for deep learning
- **OpenCV** for image processing
- **Custom model integration** support

### **Infrastructure**
- **Docker** containerization
- **PostgreSQL** primary database
- **Redis** cache and task queue
- **AWS S3** file storage
- **Prometheus + Sentry** monitoring

## Installation

### Prerequisites
- Python 3.11+
- PostgreSQL 14+
- Redis 6+
- AWS S3 bucket (for file storage)

### Setup

1. Clone the repository:
```bash
git clone <repository-url>
cd verita-ai-backend
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Copy environment variables:
```bash
cp .env.example .env
```

5. Configure your `.env` file with your database credentials and other settings.

6. Create the database:
```bash
createdb verita_ai
```

7. Run migrations:
```bash
alembic upgrade head
```

8. Start the development server:
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

9. Start the frontend (in a new terminal):
```bash
npm run dev
```

## üìö **DOCUMENTATION**

### **Complete Implementation Guide**
- **[FRONTEND_SETUP.md](FRONTEND_SETUP.md)** - Comprehensive frontend documentation
- **[RUSHIL-CHANGES.md](RUSHIL-CHANGES.md)** - Complete implementation overview and demo guide

### **Key Documentation Files**
- **Frontend Features**: All 40+ components and 15+ pages documented
- **Backend API**: 60+ endpoints with full specifications
- **AI Integration**: ML model integration and deployment guide
- **Enterprise Features**: Multi-tenancy, compliance, and scaling documentation
- **Demo Strategy**: Complete demo flow and talking points

## API Documentation

Once the server is running, you can access:
- Interactive API docs: http://localhost:8000/api/v1/docs
- Alternative API docs: http://localhost:8000/api/v1/redoc
- OpenAPI schema: http://localhost:8000/api/v1/openapi.json

## Project Structure

```
verita-ai-backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/           # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ core/          # Core functionality (config, security, deps)
‚îÇ   ‚îú‚îÄ‚îÄ db/            # Database configuration
‚îÇ   ‚îú‚îÄ‚îÄ models/        # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ schemas/       # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/      # Business logic
‚îÇ   ‚îî‚îÄ‚îÄ main.py        # FastAPI app entry point
‚îú‚îÄ‚îÄ migrations/        # Alembic migrations
‚îú‚îÄ‚îÄ tests/            # Test suite
‚îú‚îÄ‚îÄ scripts/          # Utility scripts
‚îî‚îÄ‚îÄ requirements.txt  # Python dependencies
```

## Key API Endpoints

### Authentication
- `POST /api/v1/auth/register` - Register new user
- `POST /api/v1/auth/login` - Login (returns JWT tokens)
- `POST /api/v1/auth/refresh` - Refresh access token

### Projects
- `GET /api/v1/projects` - List projects
- `POST /api/v1/projects` - Create project
- `GET /api/v1/projects/{id}` - Get project details
- `PUT /api/v1/projects/{id}` - Update project
- `DELETE /api/v1/projects/{id}` - Delete project
- `POST /api/v1/projects/{id}/launch` - Launch project
- `POST /api/v1/projects/{id}/pause` - Pause project
- `POST /api/v1/projects/{id}/questions` - Add questions

### Tasks
- `GET /api/v1/projects/{id}/tasks` - List project tasks
- `POST /api/v1/projects/{id}/tasks` - Create single task
- `POST /api/v1/projects/{id}/tasks/bulk` - Create multiple tasks
- `POST /api/v1/projects/{id}/tasks/csv` - Upload tasks via CSV
- `GET /api/v1/tasks/{id}` - Get task details
- `PUT /api/v1/tasks/{id}` - Update task
- `DELETE /api/v1/tasks/{id}` - Delete task

## Development

### Running Tests
```bash
pytest
```

### Code Formatting
```bash
black app/
flake8 app/
mypy app/
```

### Database Migrations
```bash
# Create a new migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

## Deployment

### Docker
```bash
docker build -t verita-ai-backend .
docker run -p 8000:8000 --env-file .env verita-ai-backend
```

### Production Considerations
1. Use a production ASGI server (Gunicorn with Uvicorn workers)
2. Set up a reverse proxy (Nginx)
3. Configure SSL/TLS certificates
4. Set up monitoring and logging
5. Configure automatic backups
6. Use a CDN for static assets
7. Set up rate limiting and DDoS protection

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## License

Proprietary - All rights reserved by Verita AI

## Support

For support, email support@verita.ai